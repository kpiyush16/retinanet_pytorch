{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "import time, os, copy, argparse, collections, sys, numpy as np, torch, torchvision, csv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "from anchors import Anchors\n",
    "from datagen import CSVDataset, collater, Resizer, AspectRatioBasedSampler, Augmenter, UnNormalizer, Normalizer\n",
    "from torch.utils.data import Dataset, DataLoader, distributed\n",
    "\n",
    "# Asserting torch verion to be 0.4.x\n",
    "assert torch.__version__.split('.')[1] == '4'\n",
    "from tqdm import tqdm\n",
    "# Importing our custom model file and csv evaluation\n",
    "import model, csv_eval\n",
    "\n",
    "import horovod.torch as hvd\n",
    "\n",
    "print('CUDA available: {}'.format(torch.cuda.is_available()))\n",
    "\n",
    "class Parser_arg():\n",
    "    def __init__(self, train, classes, val, savepath, steps_per_stats=100, \n",
    "                 depth=34, batch_size=16,epochs=50, resume=False):\n",
    "        self.train = train\n",
    "        self.classes = classes\n",
    "        self.val = val\n",
    "        self.steps_per_stats = steps_per_stats\n",
    "        self.savepath = savepath\n",
    "        self.depth = depth\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs= epochs\n",
    "        self.resume = resume\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing the training Dataset\n",
      "Preparing the training Dataloader\n",
      "Preparing the validation Dataset\n",
      "Preparing the validation Dataloader\n",
      "Num training images: 1935\n",
      "Num validation images: 107\n"
     ]
    }
   ],
   "source": [
    "parser = Parser_arg(train=\"data/train/train_annot.csv\",classes= \"data/class_ids.txt\",\n",
    "                val = \"data/validation/valid_annot.csv\",savepath=\"models_ao\")\n",
    "\n",
    "if not os.path.exists(parser.savepath):\n",
    "    os.makedirs(parser.savepath)\n",
    "\n",
    "# Create the data loaders\n",
    "if parser.train is None:\n",
    "    raise ValueError('Must provide --train')\n",
    "\n",
    "if parser.classes is None:\n",
    "    raise ValueError('Must provide --classes')\n",
    "\n",
    "print(\"Preparing the training Dataset\")\n",
    "\n",
    "hvd.init()\n",
    "torch.cuda.set_device(hvd.local_rank())\n",
    "kwargs = {'num_workers': 4, 'pin_memory': True} if torch.cuda.is_available() else {}\n",
    "dataset_train = CSVDataset(train_file=parser.train, class_list=parser.classes, \n",
    "                           transform=transforms.Compose([Normalizer(), Augmenter(), Resizer()]))\n",
    "\n",
    "# sampler = AspectRatioBasedSampler(dataset_train, batch_size=parser.batch_size, drop_last=False)\n",
    "train_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "    dataset_train, num_replicas=hvd.size(), rank=hvd.rank())\n",
    "\n",
    "print(\"Preparing the training Dataloader\")\n",
    "# dataloader_train = DataLoader(dataset_train, num_workers=2, collate_fn=collater, batch_sampler=sampler)\n",
    "dataloader_train = torch.utils.data.DataLoader(\n",
    "    dataset_train, batch_size=parser.batch_size,\n",
    "    sampler=train_sampler, **kwargs, collate_fn = collater)\n",
    "\n",
    "if parser.val is None:\n",
    "    dataset_val = None\n",
    "    print('No validation annotations provided.')\n",
    "else:\n",
    "    print(\"Preparing the validation Dataset\")\n",
    "    dataset_val = CSVDataset(train_file=parser.val, class_list=parser.classes, \n",
    "                             transform=transforms.Compose([Normalizer(), Resizer()]))\n",
    "\n",
    "\n",
    "if dataset_val is not None:\n",
    "    # sampler_val = AspectRatioBasedSampler(dataset_val, batch_size=parser.batch_size, drop_last=False)\n",
    "    val_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "        dataset_val, num_replicas=hvd.size(), rank=hvd.rank())    \n",
    "    print(\"Preparing the validation Dataloader\")\n",
    "    dataloader_val = torch.utils.data.DataLoader(\n",
    "        dataset_val, batch_size=parser.batch_size,\n",
    "        sampler=val_sampler, **kwargs, collate_fn = collater)\n",
    "\n",
    "print('Num training images: {}'.format(len(dataset_train)))\n",
    "if parser.val is not None:\n",
    "    print('Num validation images: {}'.format(len(dataset_val)))\n",
    "\n",
    "# Create the model\n",
    "start_epoch = 0\n",
    "if parser.resume:\n",
    "    print(\"=> loading checkpoint '{}'\".format(parser.resume))\n",
    "    checkpoint = torch.load(os.path.join(parser.savepath,'{}_retinanet_{}.pt'.format(parser.depth, parser.resume)))\n",
    "    start_epoch = checkpoint['epoch']\n",
    "\n",
    "if parser.depth == 18:\n",
    "    retinanet = model.resnet18(num_classes=dataset_train.num_classes(), pretrained=True)\n",
    "elif parser.depth == 34:\n",
    "    retinanet = model.resnet34(num_classes=dataset_train.num_classes(), pretrained=True)\n",
    "elif parser.depth == 50:\n",
    "    retinanet = model.resnet50(num_classes=dataset_train.num_classes(), pretrained=True)\n",
    "elif parser.depth == 101:\n",
    "    retinanet = model.resnet101(num_classes=dataset_train.num_classes(), pretrained=True)\n",
    "elif parser.depth == 152:\n",
    "    retinanet = model.resnet152(num_classes=dataset_train.num_classes(), pretrained=True)\n",
    "else:\n",
    "    raise ValueError('Unsupported model depth, must be one of 18, 34, 50, 101, 152')\t\t\n",
    "\n",
    "if parser.resume:\n",
    "    retinanet.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "use_gpu = True\n",
    "\n",
    "if use_gpu:\n",
    "    retinanet = retinanet.cuda()\n",
    "\n",
    "# For the MultiGPU training\n",
    "# retinanet = torch.nn.DataParallel(retinanet, device_ids=range(torch.cuda.device_count()))\n",
    "\n",
    "retinanet.training = True\n",
    "\n",
    "# \timport pdb; pdb.set_trace()\n",
    "# Broadcast parameters from rank 0 to all other processes.\n",
    "hvd.broadcast_parameters(retinanet.state_dict(), root_rank=0)\n",
    "\n",
    "optimizer = optim.Adam(retinanet.parameters(), lr=1e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, verbose=True)\n",
    "\n",
    "optimizer = hvd.DistributedOptimizer(optimizer, named_parameters=retinanet.named_parameters())\n",
    "\n",
    "if parser.resume:\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    print(\"=> loaded checkpoint {}_retinanet_{}.pt\".format(parser.depth, parser.resume))\n",
    "\n",
    "\n",
    "\n",
    "retinanet.train()\n",
    "\n",
    "retinanet.freeze_bn()\n",
    "loss_hist = collections.deque(maxlen=500)\n",
    "\n",
    "# sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch     #1: 100%|██████████| 121/121 [01:50<00:00,  1.10it/s]\n",
      "Val Epoch     #1: 100%|██████████| 7/7 [00:03<00:00,  2.37it/s]\n",
      "Train Epoch     #2: 100%|██████████| 121/121 [01:51<00:00,  1.10it/s]\n",
      "Val Epoch     #2: 100%|██████████| 7/7 [00:03<00:00,  2.31it/s]\n",
      "Train Epoch     #3: 100%|██████████| 121/121 [01:51<00:00,  1.10it/s]\n",
      "Val Epoch     #3: 100%|██████████| 7/7 [00:03<00:00,  2.32it/s]\n",
      "Train Epoch     #4: 100%|██████████| 121/121 [01:52<00:00,  1.10it/s]\n",
      "Val Epoch     #4: 100%|██████████| 7/7 [00:03<00:00,  2.28it/s]\n",
      "Train Epoch     #5: 100%|██████████| 121/121 [01:53<00:00,  1.08it/s]\n",
      "Val Epoch     #5: 100%|██████████| 7/7 [00:03<00:00,  2.26it/s]\n",
      "Train Epoch     #6: 100%|██████████| 121/121 [01:51<00:00,  1.10it/s]\n",
      "Val Epoch     #6: 100%|██████████| 7/7 [00:03<00:00,  2.06it/s]\n",
      "Train Epoch     #7: 100%|██████████| 121/121 [01:52<00:00,  1.09it/s]\n",
      "Val Epoch     #7: 100%|██████████| 7/7 [00:03<00:00,  2.15it/s]\n",
      "Train Epoch     #8: 100%|██████████| 121/121 [01:53<00:00,  1.08it/s]\n",
      "Val Epoch     #8: 100%|██████████| 7/7 [00:04<00:00,  1.92it/s]\n",
      "Train Epoch     #9: 100%|██████████| 121/121 [01:54<00:00,  1.07it/s]\n",
      "Val Epoch     #9:   0%|          | 0/7 [00:00<?, ?it/s]Process Process-83:\n",
      "Process Process-81:\n",
      "Traceback (most recent call last):\n",
      "Process Process-84:\n",
      "Process Process-82:\n",
      "  File \"/home/ai/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ai/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/ai/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ai/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ai/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ai/Documents/piyush/pytorch-retinanet/datagen.py\", line 93, in __getitem__\n",
      "    sample = self.transform(sample)\n",
      "  File \"/home/ai/anaconda3/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 49, in __call__\n",
      "    img = t(img)\n",
      "  File \"/home/ai/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ai/Documents/piyush/pytorch-retinanet/datagen.py\", line 306, in __call__\n",
      "    return {'img':((image.astype(np.float32)-self.mean)/self.std), 'annot': annots}\n",
      "  File \"/home/ai/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ai/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ai/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ai/Documents/piyush/pytorch-retinanet/datagen.py\", line 93, in __getitem__\n",
      "    sample = self.transform(sample)\n",
      "  File \"/home/ai/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ai/anaconda3/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 49, in __call__\n",
      "    img = t(img)\n",
      "  File \"/home/ai/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ai/Documents/piyush/pytorch-retinanet/datagen.py\", line 258, in __call__\n",
      "    image = skimage.transform.resize(image, (int(round(rows*scale)), int(round((cols*scale)))), mode='constant')\n",
      "  File \"/home/ai/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ai/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ai/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ai/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ai/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ai/Documents/piyush/pytorch-retinanet/datagen.py\", line 89, in __getitem__\n",
      "    img = self.load_image(idx)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-e2a5a9c2fd5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0miter_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    307\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DataLoader timed out after {} seconds'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/ai/Documents/piyush/pytorch-retinanet/datagen.py\", line 89, in __getitem__\n",
      "    img = self.load_image(idx)\n",
      "  File \"/home/ai/Documents/piyush/pytorch-retinanet/datagen.py\", line 98, in load_image\n",
      "    img = skimage.io.imread(self.image_names[image_index])\n",
      "  File \"/home/ai/anaconda3/lib/python3.6/site-packages/skimage/io/_io.py\", line 62, in imread\n",
      "    img = call_plugin('imread', fname, plugin=plugin, **plugin_args)\n",
      "  File \"/home/ai/anaconda3/lib/python3.6/site-packages/skimage/io/manage_plugins.py\", line 214, in call_plugin\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ai/anaconda3/lib/python3.6/site-packages/skimage/io/_plugins/pil_plugin.py\", line 37, in imread\n",
      "    return pil_to_ndarray(im, dtype=dtype, img_num=img_num)\n",
      "  File \"/home/ai/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py\", line 169, in resize\n",
      "    preserve_range=preserve_range)\n",
      "  File \"/home/ai/anaconda3/lib/python3.6/site-packages/skimage/io/_plugins/pil_plugin.py\", line 53, in pil_to_ndarray\n",
      "    image.getdata()[0]\n",
      "  File \"/home/ai/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py\", line 850, in warp\n",
      "    order=order, mode=mode, cval=cval))\n",
      "  File \"/home/ai/anaconda3/lib/python3.6/site-packages/PIL/Image.py\", line 1234, in getdata\n",
      "    self.load()\n",
      "  File \"skimage/transform/_warps_cy.pyx\", line 131, in skimage.transform._warps_cy._warp_fast\n",
      "  File \"/home/ai/anaconda3/lib/python3.6/site-packages/PIL/ImageFile.py\", line 235, in load\n",
      "    n, err_code = decoder.decode(b)\n",
      "  File \"/home/ai/anaconda3/lib/python3.6/site-packages/numpy/core/numeric.py\", line 433, in asarray\n",
      "    def asarray(a, dtype=None, order=None):\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ai/Documents/piyush/pytorch-retinanet/datagen.py\", line 98, in load_image\n",
      "    img = skimage.io.imread(self.image_names[image_index])\n",
      "  File \"/home/ai/anaconda3/lib/python3.6/site-packages/skimage/io/_io.py\", line 62, in imread\n",
      "    img = call_plugin('imread', fname, plugin=plugin, **plugin_args)\n",
      "  File \"/home/ai/anaconda3/lib/python3.6/site-packages/skimage/io/manage_plugins.py\", line 214, in call_plugin\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ai/anaconda3/lib/python3.6/site-packages/skimage/io/_plugins/pil_plugin.py\", line 37, in imread\n",
      "    return pil_to_ndarray(im, dtype=dtype, img_num=img_num)\n",
      "  File \"/home/ai/anaconda3/lib/python3.6/site-packages/skimage/io/_plugins/pil_plugin.py\", line 53, in pil_to_ndarray\n",
      "    image.getdata()[0]\n",
      "  File \"/home/ai/anaconda3/lib/python3.6/site-packages/PIL/Image.py\", line 1234, in getdata\n",
      "    self.load()\n",
      "  File \"/home/ai/anaconda3/lib/python3.6/site-packages/PIL/ImageFile.py\", line 235, in load\n",
      "    n, err_code = decoder.decode(b)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "verbose = 1 if hvd.rank() == 0 else 0\n",
    "for epoch_num in range(start_epoch+1,parser.epochs):\n",
    "    with tqdm(total=len(dataloader_train), desc='Train Epoch     #{}'.format(epoch_num), disable=not verbose) as t:\n",
    "        retinanet.train()\n",
    "        retinanet.freeze_bn()\n",
    "        epoch_loss, cls_loss_lst, reg_loss_lst = [], [], []\n",
    "        stime = time.time()\n",
    "        for iter_num, data in enumerate(dataloader_train):\n",
    "            try:\n",
    "                img, annot = data['img'].cuda(), data['annot'].cuda()\n",
    "                optimizer.zero_grad()\n",
    "                classification_loss, regression_loss = retinanet([img, annot])\n",
    "                cls_loss_lst.append(float(classification_loss))\n",
    "                reg_loss_lst.append(float(regression_loss))\n",
    "                classification_loss = classification_loss.mean()\n",
    "                regression_loss = regression_loss.mean()\n",
    "                loss = classification_loss + regression_loss\n",
    "                if bool(loss == 0):\n",
    "                    continue\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(retinanet.parameters(), 0.1)\n",
    "                optimizer.step()\n",
    "                loss_hist.append(float(loss))\n",
    "                epoch_loss.append(float(loss))\n",
    "                if(iter_num % parser.steps_per_stats == 0):\n",
    "                    st = 'Epoch: {} | Iter: {} | Ela_time: {:1.5f} | Cls_loss: {:1.5f} | Reg_loss: {:1.5f} | Avg_running_loss: {:1.5f}'.format(epoch_num, iter_num, time.time()-stime, np.mean(cls_loss_lst), np.mean(reg_loss_lst), np.mean(loss_hist))\n",
    "                    with open(os.path.join(parser.savepath, 'train_log.txt'), 'a') as f:\n",
    "                        f.write(st+\"\\n\")\n",
    "                    cls_loss_lst, reg_loss_lst, stime = [], [], time.time()\n",
    "\n",
    "                del classification_loss\n",
    "                del regression_loss\n",
    "                t.update(1)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                continue\n",
    "\n",
    "    if parser.val is not None:\n",
    "        with tqdm(total=len(dataloader_val), desc='Val Epoch     #{}'.format(epoch_num), disable=not verbose) as t:\n",
    "\n",
    "            val_loss = []\n",
    "            for iter_num, data in enumerate(dataloader_val):\n",
    "                try:\n",
    "                    optimizer.zero_grad()\n",
    "                    img, annot = data['img'].cuda(), data['annot'].cuda()\n",
    "                    classification_loss, regression_loss = retinanet([img, annot])\n",
    "                    classification_loss = classification_loss.mean()\n",
    "                    regression_loss = regression_loss.mean()\n",
    "                    val_loss.append(float(classification_loss + regression_loss))\n",
    "                    if bool(loss == 0):\n",
    "                        continue\n",
    "                    del classification_loss\n",
    "                    del regression_loss\n",
    "                    t.update(1)\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    continue\n",
    "                    \n",
    "        t.set_postfix({'epoch':epoch_num, 'train_loss': np.mean(epoch_loss),\n",
    "                           'val_loss': np.mean(val_loss)})\n",
    "        t.update(1)\n",
    "\n",
    "        scheduler.step(np.mean(epoch_loss))\t\n",
    "        torch.save({'epoch':epoch_num,\n",
    "        'model_state_dict':retinanet.state_dict(),\n",
    "        'optimizer_state_dict':optimizer.state_dict(),\n",
    "        'loss':loss}, os.path.join(parser.savepath,'{}_retinanet_{}.pt'.format(parser.depth, epoch_num)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing the training Dataloader\n"
     ]
    }
   ],
   "source": [
    "parser = Parser_arg(train=\"data/train/train_annot.csv\",classes= \"data/class_ids.txt\",\n",
    "                val = \"data/validation/valid_annot.csv\",savepath=\"models_ao\")\n",
    "hvd.init()\n",
    "torch.cuda.set_device(hvd.local_rank())\n",
    "kwargs = {'num_workers': 4, 'pin_memory': True} if torch.cuda.is_available() else {}\n",
    "dataset_train = CSVDataset(train_file=parser.train, class_list=parser.classes, \n",
    "                           transform=transforms.Compose([Normalizer(), Augmenter(), Resizer()]))\n",
    "\n",
    "# sampler = AspectRatioBasedSampler(dataset_train, batch_size=parser.batch_size, drop_last=False)\n",
    "train_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "    dataset_train, num_replicas=hvd.size(), rank=hvd.rank())\n",
    "\n",
    "print(\"Preparing the training Dataloader\")\n",
    "# dataloader_train = DataLoader(dataset_train, num_workers=2, collate_fn=collater, batch_sampler=sampler)\n",
    "dataloader_train = torch.utils.data.DataLoader(\n",
    "    dataset_train, batch_size=parser.batch_size,\n",
    "    sampler=train_sampler, **kwargs, collate_fn = collater)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch     #0: 100%|██████████| 5/5 [00:02<00:00,  1.99it/s]\n",
      "Epoch     #1:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch     #1: 100%|██████████| 5/5 [00:02<00:00,  1.99it/s]\n",
      "Epoch     #2:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch     #2: 100%|██████████| 5/5 [00:02<00:00,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch_num in range(0, 3):\n",
    "    with tqdm(total=5, desc='Epoch     #{}'.format(epoch_num), disable=not verbose) as t:\n",
    "        for i in range(5):\n",
    "            time.sleep(0.5)\n",
    "            t.update(1)\n",
    "        t.write(\"Hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
